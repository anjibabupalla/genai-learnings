{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzdCdgt/2M2XrlzQUQoP2t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UFNmJpTBhtg-"},"outputs":[],"source":["!pip install openai colorama"]},{"cell_type":"markdown","source":["# MultiAgent Pattern"],"metadata":{"id":"pgu2j3Eo5RQX"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=16Fjbqg5a1Yl6x1pPhcL4uVuS0JRacdrm\" alt=\"Alt text\" width=\"500\"/>\n","\n","---\n","\n","You may have heard about frameworks like [CrewAI](https://www.crewai.com/) or [AutoGen](https://microsoft.github.io/autogen/0.2/), which allow you to create multi-agent applications.\n","\n","These frameworks implement different variations of the multi-agent pattern, in which tasks are divided into **smaller subtasks executed by different roles** (e.g. one agent can be a software engineer, another a project manager, etc.)\n","\n","For this final lesson, I wanted to build something more elaborate. That's why I've been working on a 𝐦𝐢𝐧𝐢𝐦𝐚𝐥𝐢𝐬𝐭 𝐯𝐞𝐫𝐬𝐢𝐨𝐧 𝐨𝐟 𝐂𝐫𝐞𝐰𝐀𝐈, drawing inspiration from two of its key concepts: 𝐂𝐫𝐞𝐰 and 𝐀𝐠𝐞𝐧𝐭.\n","\n","Additionally, I've also borrowed ideas from [𝐀𝐢𝐫𝐟𝐥𝐨𝐰](https://airflow.apache.org/)'𝐬 𝐝𝐞𝐬𝐢𝐠𝐧 𝐩𝐡𝐢𝐥𝐨𝐬𝐨𝐩𝐡𝐲, using >> and << to define dependencies between my agents. In this micro-CrewAI, 𝐚𝐠𝐞𝐧𝐭𝐬 are equivalent to 𝐀𝐢𝐫𝐟𝐥𝐨𝐰 𝐓𝐚𝐬𝐤𝐬 and the 𝐂𝐫𝐞𝐰 is equivalent to an 𝐀𝐢𝐫𝐟𝐥𝐨𝐰 𝐃𝐀𝐆."],"metadata":{"id":"oF68_nzn5ePX"}},{"cell_type":"markdown","source":["## The Agent Class"],"metadata":{"id":"bC-of0JG61g-"}},{"cell_type":"markdown","source":["First of all, we need an **Agent Class**. This class implements an\n","Agent, and internally it implements the ReAct technique. We'll also need to import all the code related with the Tools from Module 3 and additional helpers."],"metadata":{"id":"X68_V9N0632f"}},{"cell_type":"markdown","source":["#### General Helpers"],"metadata":{"id":"-BTG_bdcBnzp"}},{"cell_type":"code","source":["# @title\n","import re\n","import time\n","\n","from colorama import Fore\n","from colorama import Style\n","\n","from graphviz import Digraph  # type: ignore\n","\n","from dataclasses import dataclass\n","\n","\n","def completions_create(client, messages: list, model: str) -> str:\n","    \"\"\"\n","    Sends a request to the client's `completions.create` method to interact with the language model.\n","\n","    Args:\n","        client (OpenAI): The OpenAI client object\n","        messages (list[dict]): A list of message objects containing chat history for the model.\n","        model (str): The model to use for generating tool calls and responses.\n","\n","    Returns:\n","        str: The content of the model's response.\n","    \"\"\"\n","    response = client.chat.completions.create(messages=messages, model=model)\n","    return str(response.choices[0].message.content)\n","\n","\n","def build_prompt_structure(prompt: str, role: str, tag: str = \"\") -> dict:\n","    \"\"\"\n","    Builds a structured prompt that includes the role and content.\n","\n","    Args:\n","        prompt (str): The actual content of the prompt.\n","        role (str): The role of the speaker (e.g., user, assistant).\n","\n","    Returns:\n","        dict: A dictionary representing the structured prompt.\n","    \"\"\"\n","    if tag:\n","        prompt = f\"<{tag}>{prompt}</{tag}>\"\n","    return {\"role\": role, \"content\": prompt}\n","\n","def update_chat_history(history: list, msg: str, role: str):\n","    \"\"\"\n","    Updates the chat history by appending the latest response.\n","\n","    Args:\n","        history (list): The list representing the current chat history.\n","        msg (str): The message to append.\n","        role (str): The role type (e.g. 'user', 'assistant', 'system')\n","    \"\"\"\n","    history.append(build_prompt_structure(prompt=msg, role=role))\n","\n","\n","class ChatHistory(list):\n","    def __init__(self, messages: list | None = None, total_length: int = -1):\n","        \"\"\"Initialise the queue with a fixed total length.\n","\n","        Args:\n","            messages (list | None): A list of initial messages\n","            total_length (int): The maximum number of messages the chat history can hold.\n","        \"\"\"\n","        if messages is None:\n","            messages = []\n","\n","        super().__init__(messages)\n","        self.total_length = total_length\n","\n","    def append(self, msg: str):\n","        \"\"\"Add a message to the queue.\n","\n","        Args:\n","            msg (str): The message to be added to the queue\n","        \"\"\"\n","        if len(self) == self.total_length:\n","            self.pop(0)\n","        super().append(msg)\n","\n","\n","\n","class FixedFirstChatHistory(ChatHistory):\n","    def __init__(self, messages: list | None = None, total_length: int = -1):\n","        \"\"\"Initialise the queue with a fixed total length.\n","\n","        Args:\n","            messages (list | None): A list of initial messages\n","            total_length (int): The maximum number of messages the chat history can hold.\n","        \"\"\"\n","        super().__init__(messages, total_length)\n","\n","    def append(self, msg: str):\n","        \"\"\"Add a message to the queue. The first messaage will always stay fixed.\n","\n","        Args:\n","            msg (str): The message to be added to the queue\n","        \"\"\"\n","        if len(self) == self.total_length:\n","            self.pop(1)\n","        super().append(msg)\n","\n","def fancy_print(message: str) -> None:\n","    \"\"\"\n","    Displays a fancy print message.\n","\n","    Args:\n","        message (str): The message to display.\n","    \"\"\"\n","    print(Style.BRIGHT + Fore.CYAN + f\"\\n{'=' * 50}\")\n","    print(Fore.MAGENTA + f\"{message}\")\n","    print(Style.BRIGHT + Fore.CYAN + f\"{'=' * 50}\\n\")\n","    time.sleep(0.5)\n","\n","\n","def fancy_step_tracker(step: int, total_steps: int) -> None:\n","    \"\"\"\n","    Displays a fancy step tracker for each iteration of the generation-reflection loop.\n","\n","    Args:\n","        step (int): The current step in the loop.\n","        total_steps (int): The total number of steps in the loop.\n","    \"\"\"\n","    fancy_print(f\"STEP {step + 1}/{total_steps}\")\n","\n","\n","@dataclass\n","class TagContentResult:\n","    \"\"\"\n","    A data class to represent the result of extracting tag content.\n","\n","    Attributes:\n","        content (List[str]): A list of strings containing the content found between the specified tags.\n","        found (bool): A flag indicating whether any content was found for the given tag.\n","    \"\"\"\n","\n","    content: list[str]\n","    found: bool\n","\n","\n","def extract_tag_content(text: str, tag: str) -> TagContentResult:\n","    \"\"\"\n","    Extracts all content enclosed by specified tags (e.g., <thought>, <response>, etc.).\n","\n","    Parameters:\n","        text (str): The input string containing multiple potential tags.\n","        tag (str): The name of the tag to search for (e.g., 'thought', 'response').\n","\n","    Returns:\n","        dict: A dictionary with the following keys:\n","            - 'content' (list): A list of strings containing the content found between the specified tags.\n","            - 'found' (bool): A flag indicating whether any content was found for the given tag.\n","    \"\"\"\n","    # Build the regex pattern dynamically to find multiple occurrences of the tag\n","    tag_pattern = rf\"<{tag}>(.*?)</{tag}>\"\n","\n","    # Use findall to capture all content between the specified tag\n","    matched_contents = re.findall(tag_pattern, text, re.DOTALL)\n","\n","    # Return the dataclass instance with the result\n","    return TagContentResult(\n","        content=[content.strip() for content in matched_contents],\n","        found=bool(matched_contents),\n","    )\n","\n","class Crew:\n","    \"\"\"\n","    A class representing a crew of agents working together.\n","\n","    This class manages a group of agents, their dependencies, and provides methods\n","    for running the agents in a topologically sorted order.\n","\n","    Attributes:\n","        current_crew (Crew): Class-level variable to track the active Crew context.\n","        agents (list): A list of agents in the crew.\n","    \"\"\"\n","\n","    current_crew = None\n","\n","    def __init__(self):\n","        self.agents = []\n","\n","    def __enter__(self):\n","        \"\"\"\n","        Enters the context manager, setting this crew as the current active context.\n","\n","        Returns:\n","            Crew: The current Crew instance.\n","        \"\"\"\n","        Crew.current_crew = self\n","        return self\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        \"\"\"\n","        Exits the context manager, clearing the active context.\n","\n","        Args:\n","            exc_type: The exception type, if an exception was raised.\n","            exc_val: The exception value, if an exception was raised.\n","            exc_tb: The traceback, if an exception was raised.\n","        \"\"\"\n","        Crew.current_crew = None\n","\n","    def add_agent(self, agent):\n","        \"\"\"\n","        Adds an agent to the crew.\n","\n","        Args:\n","            agent: The agent to be added to the crew.\n","        \"\"\"\n","        self.agents.append(agent)\n","\n","    @staticmethod\n","    def register_agent(agent):\n","        \"\"\"\n","        Registers an agent with the current active crew context.\n","\n","        Args:\n","            agent: The agent to be registered.\n","        \"\"\"\n","        if Crew.current_crew is not None:\n","            Crew.current_crew.add_agent(agent)\n","\n","    def topological_sort(self):\n","        \"\"\"\n","        Performs a topological sort of the agents based on their dependencies.\n","\n","        Returns:\n","            list: A list of agents sorted in topological order.\n","\n","        Raises:\n","            ValueError: If there's a circular dependency among the agents.\n","        \"\"\"\n","        in_degree = {agent: len(agent.dependencies) for agent in self.agents}\n","        queue = deque([agent for agent in self.agents if in_degree[agent] == 0])\n","\n","        sorted_agents = []\n","\n","        while queue:\n","            current_agent = queue.popleft()\n","            sorted_agents.append(current_agent)\n","\n","            for dependent in current_agent.dependents:\n","                in_degree[dependent] -= 1\n","                if in_degree[dependent] == 0:\n","                    queue.append(dependent)\n","\n","        if len(sorted_agents) != len(self.agents):\n","            raise ValueError(\n","                \"Circular dependencies detected among agents, preventing a valid topological sort\"\n","            )\n","\n","        return sorted_agents\n","\n","    def plot(self):\n","        \"\"\"\n","        Plots the Directed Acyclic Graph (DAG) of agents in the crew using Graphviz.\n","\n","        Returns:\n","            Digraph: A Graphviz Digraph object representing the agent dependencies.\n","        \"\"\"\n","        dot = Digraph(format=\"png\")  # Set format to PNG for inline display\n","\n","        # Add nodes and edges for each agent in the crew\n","        for agent in self.agents:\n","            dot.node(agent.name)\n","            for dependency in agent.dependencies:\n","                dot.edge(dependency.name, agent.name)\n","        return dot\n","\n","    def run(self):\n","        \"\"\"\n","        Runs all agents in the crew in topologically sorted order.\n","\n","        This method executes each agent's run method and prints the results.\n","        \"\"\"\n","        sorted_agents = self.topological_sort()\n","        for agent in sorted_agents:\n","            fancy_print(f\"RUNNING AGENT: {agent}\")\n","            print(Fore.RED + f\"{agent.run()}\")\n"],"metadata":{"cellView":"form","id":"eML6xI3yB2no"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Tools"],"metadata":{"id":"1aTVf2xhBY3t"}},{"cell_type":"code","source":["# @title\n","import json\n","import re\n","from dataclasses import dataclass\n","from typing import Callable\n","\n","\n","def get_fn_signature(fn: Callable) -> dict:\n","    \"\"\"\n","    Generates the signature for a given function.\n","\n","    Args:\n","        fn (Callable): The function whose signature needs to be extracted.\n","\n","    Returns:\n","        dict: A dictionary containing the function's name, description,\n","              and parameter types.\n","    \"\"\"\n","    fn_signature: dict = {\n","        \"name\": fn.__name__,\n","        \"description\": fn.__doc__,\n","        \"parameters\": {\"properties\": {}},\n","    }\n","    schema = {\n","        k: {\"type\": v.__name__} for k, v in fn.__annotations__.items() if k != \"return\"\n","    }\n","    fn_signature[\"parameters\"][\"properties\"] = schema\n","    return fn_signature\n","\n","\n","def validate_arguments(tool_call: dict, tool_signature: dict) -> dict:\n","    \"\"\"\n","    Validates and converts arguments in the input dictionary to match the expected types.\n","\n","    Args:\n","        tool_call (dict): A dictionary containing the arguments passed to the tool.\n","        tool_signature (dict): The expected function signature and parameter types.\n","\n","    Returns:\n","        dict: The tool call dictionary with the arguments converted to the correct types if necessary.\n","    \"\"\"\n","    properties = tool_signature[\"parameters\"][\"properties\"]\n","\n","    # TODO: This is overly simplified but enough for simple Tools.\n","    type_mapping = {\n","        \"int\": int,\n","        \"str\": str,\n","        \"bool\": bool,\n","        \"float\": float,\n","    }\n","\n","    for arg_name, arg_value in tool_call[\"arguments\"].items():\n","        expected_type = properties[arg_name].get(\"type\")\n","\n","        if not isinstance(arg_value, type_mapping[expected_type]):\n","            tool_call[\"arguments\"][arg_name] = type_mapping[expected_type](arg_value)\n","\n","    return tool_call\n","\n","\n","class Tool:\n","    \"\"\"\n","    A class representing a tool that wraps a callable and its signature.\n","\n","    Attributes:\n","        name (str): The name of the tool (function).\n","        fn (Callable): The function that the tool represents.\n","        fn_signature (str): JSON string representation of the function's signature.\n","    \"\"\"\n","\n","    def __init__(self, name: str, fn: Callable, fn_signature: str):\n","        self.name = name\n","        self.fn = fn\n","        self.fn_signature = fn_signature\n","\n","    def __str__(self):\n","        return self.fn_signature\n","\n","    def run(self, **kwargs):\n","        \"\"\"\n","        Executes the tool (function) with provided arguments.\n","\n","        Args:\n","            **kwargs: Keyword arguments passed to the function.\n","\n","        Returns:\n","            The result of the function call.\n","        \"\"\"\n","        return self.fn(**kwargs)\n","\n","\n","def tool(fn: Callable):\n","    \"\"\"\n","    A decorator that wraps a function into a Tool object.\n","\n","    Args:\n","        fn (Callable): The function to be wrapped.\n","\n","    Returns:\n","        Tool: A Tool object containing the function, its name, and its signature.\n","    \"\"\"\n","\n","    def wrapper():\n","        fn_signature = get_fn_signature(fn)\n","        return Tool(\n","            name=fn_signature.get(\"name\"), fn=fn, fn_signature=json.dumps(fn_signature)\n","        )\n","\n","    return wrapper()\n","\n","\n","@dataclass\n","class TagContentResult:\n","    \"\"\"\n","    A data class to represent the result of extracting tag content.\n","\n","    Attributes:\n","        content (List[str]): A list of strings containing the content found between the specified tags.\n","        found (bool): A flag indicating whether any content was found for the given tag.\n","    \"\"\"\n","\n","    content: list[str]\n","    found: bool\n","\n","\n","def extract_tag_content(text: str, tag: str) -> TagContentResult:\n","    \"\"\"\n","    Extracts all content enclosed by specified tags (e.g., <thought>, <response>, etc.).\n","\n","    Parameters:\n","        text (str): The input string containing multiple potential tags.\n","        tag (str): The name of the tag to search for (e.g., 'thought', 'response').\n","\n","    Returns:\n","        dict: A dictionary with the following keys:\n","            - 'content' (list): A list of strings containing the content found between the specified tags.\n","            - 'found' (bool): A flag indicating whether any content was found for the given tag.\n","    \"\"\"\n","    # Build the regex pattern dynamically to find multiple occurrences of the tag\n","    tag_pattern = rf\"<{tag}>(.*?)</{tag}>\"\n","\n","    # Use findall to capture all content between the specified tag\n","    matched_contents = re.findall(tag_pattern, text, re.DOTALL)\n","\n","    # Return the dataclass instance with the result\n","    return TagContentResult(\n","        content=[content.strip() for content in matched_contents],\n","        found=bool(matched_contents),\n","    )"],"metadata":{"cellView":"form","id":"juB8xuPfBXhf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ReAct Agent"],"metadata":{"id":"Jgw-WmKXBlpH"}},{"cell_type":"code","source":["# @title\n","import json\n","import re\n","\n","from colorama import Fore\n","\n","BASE_SYSTEM_PROMPT = \"\"\n","\n","\n","REACT_SYSTEM_PROMPT = \"\"\"\n","You operate by running a loop with the following steps: Thought, Action, Observation.\n","You are provided with function signatures within <tools></tools> XML tags.\n","You may call one or more functions to assist with the user query. Don' make assumptions about what values to plug\n","into functions. Pay special attention to the properties 'types'. You should use those types as in a Python dict.\n","\n","For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n","\n","<tool_call>\n","{\"name\": <function-name>,\"arguments\": <args-dict>, \"id\": <monotonically-increasing-id>}\n","</tool_call>\n","\n","Here are the available tools / actions:\n","\n","<tools>\n","%s\n","</tools>\n","\n","Example session:\n","\n","<question>What's the current temperature in Madrid?</question>\n","<thought>I need to get the current weather in Madrid</thought>\n","<tool_call>{\"name\": \"get_current_weather\",\"arguments\": {\"location\": \"Madrid\", \"unit\": \"celsius\"}, \"id\": 0}</tool_call>\n","\n","You will be called again with this:\n","\n","<observation>{0: {\"temperature\": 25, \"unit\": \"celsius\"}}</observation>\n","\n","You then output:\n","\n","<response>The current temperature in Madrid is 25 degrees Celsius</response>\n","\n","Additional constraints:\n","\n","- If the user asks you something unrelated to any of the tools above, answer freely enclosing your answer with <response></response> tags.\n","\"\"\"\n","\n","\n","class ReactAgent:\n","    \"\"\"\n","    A class that represents an agent using the ReAct logic that interacts with tools to process\n","    user inputs, make decisions, and execute tool calls. The agent can run interactive sessions,\n","    collect tool signatures, and process multiple tool calls in a given round of interaction.\n","\n","    Attributes:\n","        client (OpenAI): The OpenAI client used to handle model-based completions.\n","        model (str): The name of the model used for generating responses. Default is \"gpt-4o\".\n","        tools (list[Tool]): A list of Tool instances available for execution.\n","        tools_dict (dict): A dictionary mapping tool names to their corresponding Tool instances.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        tools: Tool | list[Tool],\n","        model: str = \"gpt-4o\",\n","        system_prompt: str = BASE_SYSTEM_PROMPT,\n","    ) -> None:\n","        self.client = OpenAI(\n","            api_key=userdata.get('OPENAI_API_KEY')\n","        )\n","        self.model = model\n","        self.system_prompt = system_prompt\n","        self.tools = tools if isinstance(tools, list) else [tools]\n","        self.tools_dict = {tool.name: tool for tool in self.tools}\n","\n","    def add_tool_signatures(self) -> str:\n","        \"\"\"\n","        Collects the function signatures of all available tools.\n","\n","        Returns:\n","            str: A concatenated string of all tool function signatures in JSON format.\n","        \"\"\"\n","        return \"\".join([tool.fn_signature for tool in self.tools])\n","\n","    def process_tool_calls(self, tool_calls_content: list) -> dict:\n","        \"\"\"\n","        Processes each tool call, validates arguments, executes the tools, and collects results.\n","\n","        Args:\n","            tool_calls_content (list): List of strings, each representing a tool call in JSON format.\n","\n","        Returns:\n","            dict: A dictionary where the keys are tool call IDs and values are the results from the tools.\n","        \"\"\"\n","        observations = {}\n","        for tool_call_str in tool_calls_content:\n","            tool_call = json.loads(tool_call_str)\n","            tool_name = tool_call[\"name\"]\n","            tool = self.tools_dict[tool_name]\n","\n","            print(Fore.GREEN + f\"\\nUsing Tool: {tool_name}\")\n","\n","            # Validate and execute the tool call\n","            validated_tool_call = validate_arguments(\n","                tool_call, json.loads(tool.fn_signature)\n","            )\n","            print(Fore.GREEN + f\"\\nTool call dict: \\n{validated_tool_call}\")\n","\n","            result = tool.run(**validated_tool_call[\"arguments\"])\n","            print(Fore.GREEN + f\"\\nTool result: \\n{result}\")\n","\n","            # Store the result using the tool call ID\n","            observations[validated_tool_call[\"id\"]] = result\n","\n","        return observations\n","\n","    def run(\n","        self,\n","        user_msg: str,\n","        max_rounds: int = 10,\n","    ) -> str:\n","        \"\"\"\n","        Executes a user interaction session, where the agent processes user input, generates responses,\n","        handles tool calls, and updates chat history until a final response is ready or the maximum\n","        number of rounds is reached.\n","\n","        Args:\n","            user_msg (str): The user's input message to start the interaction.\n","            max_rounds (int, optional): Maximum number of interaction rounds the agent should perform. Default is 10.\n","\n","        Returns:\n","            str: The final response generated by the agent after processing user input and any tool calls.\n","        \"\"\"\n","        user_prompt = build_prompt_structure(\n","            prompt=user_msg, role=\"user\", tag=\"question\"\n","        )\n","        if self.tools:\n","            self.system_prompt += (\n","                \"\\n\" + REACT_SYSTEM_PROMPT % self.add_tool_signatures()\n","            )\n","\n","        chat_history = ChatHistory(\n","            [\n","                build_prompt_structure(\n","                    prompt=self.system_prompt,\n","                    role=\"system\",\n","                ),\n","                user_prompt,\n","            ]\n","        )\n","\n","        if self.tools:\n","            # Run the ReAct loop for max_rounds\n","            for _ in range(max_rounds):\n","\n","                completion = completions_create(self.client, chat_history, self.model)\n","\n","                response = extract_tag_content(str(completion), \"response\")\n","                if response.found:\n","                    return response.content[0]\n","\n","                thought = extract_tag_content(str(completion), \"thought\")\n","                tool_calls = extract_tag_content(str(completion), \"tool_call\")\n","\n","                update_chat_history(chat_history, completion, \"assistant\")\n","\n","                print(Fore.MAGENTA + f\"\\nThought: {thought.content[0]}\")\n","\n","                if tool_calls.found:\n","                    observations = self.process_tool_calls(tool_calls.content)\n","                    print(Fore.BLUE + f\"\\nObservations: {observations}\")\n","                    update_chat_history(chat_history, f\"{observations}\", \"user\")\n","\n","        return completions_create(self.client, chat_history, self.model)"],"metadata":{"cellView":"form","id":"TaGc-RyzB9oq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that we have all the relevant code from previous modules imported, it's time to define the Agent."],"metadata":{"id":"WuyjHz8lCA8C"}},{"cell_type":"code","source":["from openai import OpenAI\n","from google.colab import userdata\n","from textwrap import dedent\n","\n","class Agent:\n","    \"\"\"\n","    Represents an AI agent that can work as part of a team to complete tasks.\n","\n","    This class implements an agent with dependencies, context handling, and task execution capabilities.\n","    It can be used in a multi-agent system where agents collaborate to solve complex problems.\n","\n","    Attributes:\n","        name (str): The name of the agent.\n","        backstory (str): The backstory or background of the agent.\n","        task_description (str): A description of the task assigned to the agent.\n","        task_expected_output (str): The expected format or content of the task output.\n","        react_agent (ReactAgent): An instance of ReactAgent used for generating responses.\n","        dependencies (list[Agent]): A list of Agent instances that this agent depends on.\n","        dependents (list[Agent]): A list of Agent instances that depend on this agent.\n","        context (str): Accumulated context information from other agents.\n","\n","    Args:\n","        name (str): The name of the agent.\n","        backstory (str): The backstory or background of the agent.\n","        task_description (str): A description of the task assigned to the agent.\n","        task_expected_output (str, optional): The expected format or content of the task output. Defaults to \"\".\n","        tools (list[Tool] | None, optional): A list of Tool instances available to the agent. Defaults to None.\n","        llm (str, optional): The name of the language model to use. Defaults to \"gpt-4o\".\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        name: str,\n","        backstory: str,\n","        task_description: str,\n","        task_expected_output: str = \"\",\n","        tools: list[Tool] | None = None,\n","        llm: str = \"gpt-4o\",\n","    ):\n","        self.name = name\n","        self.backstory = backstory\n","        self.task_description = task_description\n","        self.task_expected_output = task_expected_output\n","        self.react_agent = ReactAgent(\n","            model=llm, system_prompt=self.backstory, tools=tools or []\n","        )\n","\n","        self.dependencies: list[Agent] = []  # Agents that this agent depends on\n","        self.dependents: list[Agent] = []  # Agents that depend on this agent\n","\n","        self.context = \"\"\n","\n","        # Automatically register this agent to the active Crew context if one exists\n","        Crew.register_agent(self)\n","\n","    def __repr__(self):\n","        return f\"{self.name}\"\n","\n","    def __rshift__(self, other):\n","        \"\"\"\n","        Defines the '>>' operator. This operator is used to indicate agent dependency.\n","\n","        Args:\n","            other (Agent): The agent that depends on this agent.\n","        \"\"\"\n","        self.add_dependent(other)\n","        return other  # Allow chaining\n","\n","    def __lshift__(self, other):\n","        \"\"\"\n","        Defines the '<<' operator to indicate agent dependency in reverse.\n","\n","        Args:\n","            other (Agent): The agent that this agent depends on.\n","\n","        Returns:\n","            Agent: The `other` agent to allow for chaining.\n","        \"\"\"\n","        self.add_dependency(other)\n","        return other  # Allow chaining\n","\n","    def __rrshift__(self, other):\n","        \"\"\"\n","        Defines the '<<' operator.This operator is used to indicate agent dependency.\n","\n","        Args:\n","            other (Agent): The agent that this agent depends on.\n","        \"\"\"\n","        self.add_dependency(other)\n","        return self  # Allow chaining\n","\n","    def __rlshift__(self, other):\n","        \"\"\"\n","        Defines the '<<' operator when evaluated from right to left.\n","        This operator is used to indicate agent dependency in the normal order.\n","\n","        Args:\n","            other (Agent): The agent that depends on this agent.\n","\n","        Returns:\n","            Agent: The current agent (self) to allow for chaining.\n","        \"\"\"\n","        self.add_dependent(other)\n","        return self  # Allow chaining\n","\n","    def add_dependency(self, other):\n","        \"\"\"\n","        Adds a dependency to this agent.\n","\n","        Args:\n","            other (Agent | list[Agent]): The agent(s) that this agent depends on.\n","\n","        Raises:\n","            TypeError: If the dependency is not an Agent or a list of Agents.\n","        \"\"\"\n","        if isinstance(other, Agent):\n","            self.dependencies.append(other)\n","            other.dependents.append(self)\n","        elif isinstance(other, list) and all(isinstance(item, Agent) for item in other):\n","            for item in other:\n","                self.dependencies.append(item)\n","                item.dependents.append(self)\n","        else:\n","            raise TypeError(\"The dependency must be an instance or list of Agent.\")\n","\n","    def add_dependent(self, other):\n","        \"\"\"\n","        Adds a dependent to this agent.\n","\n","        Args:\n","            other (Agent | list[Agent]): The agent(s) that depend on this agent.\n","\n","        Raises:\n","            TypeError: If the dependent is not an Agent or a list of Agents.\n","        \"\"\"\n","        if isinstance(other, Agent):\n","            other.dependencies.append(self)\n","            self.dependents.append(other)\n","        elif isinstance(other, list) and all(isinstance(item, Agent) for item in other):\n","            for item in other:\n","                item.dependencies.append(self)\n","                self.dependents.append(item)\n","        else:\n","            raise TypeError(\"The dependent must be an instance or list of Agent.\")\n","\n","    def receive_context(self, input_data):\n","        \"\"\"\n","        Receives and stores context information from other agents.\n","\n","        Args:\n","            input_data (str): The context information to be added.\n","        \"\"\"\n","        self.context += f\"{self.name} received context: \\n{input_data}\"\n","\n","    def create_prompt(self):\n","        \"\"\"\n","        Creates a prompt for the agent based on its task description, expected output, and context.\n","\n","        Returns:\n","            str: The formatted prompt string.\n","        \"\"\"\n","        prompt = dedent(\n","            f\"\"\"\n","        You are an AI agent. You are part of a team of agents working together to complete a task.\n","        I'm going to give you the task description enclosed in <task_description></task_description> tags. I'll also give\n","        you the available context from the other agents in <context></context> tags. If the context\n","        is not available, the <context></context> tags will be empty. You'll also receive the task\n","        expected output enclosed in <task_expected_output></task_expected_output> tags. With all this information\n","        you need to create the best possible response, always respecting the format as describe in\n","        <task_expected_output></task_expected_output> tags. If expected output is not available, just create\n","        a meaningful response to complete the task.\n","\n","        <task_description>\n","        {self.task_description}\n","        </task_description>\n","\n","        <task_expected_output>\n","        {self.task_expected_output}\n","        </task_expected_output>\n","\n","        <context>\n","        {self.context}\n","        </context>\n","\n","        Your response:\n","        \"\"\"\n","        ).strip()\n","\n","        return prompt\n","\n","    def run(self):\n","        \"\"\"\n","        Runs the agent's task and generates the output.\n","\n","        This method creates a prompt, runs it through the ReactAgent, and passes the output to all dependent agents.\n","\n","        Returns:\n","            str: The output generated by the agent.\n","        \"\"\"\n","        msg = self.create_prompt()\n","        output = self.react_agent.run(user_msg=msg)\n","\n","        # Pass the output to all dependents\n","        for dependent in self.dependents:\n","            dependent.receive_context(output)\n","        return output\n"],"metadata":{"id":"9Cl2iAov65SU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's create some example agent, to see how it works."],"metadata":{"id":"Jqm8VOU0CiKF"}},{"cell_type":"code","source":["agent_example = Agent(\n","    name=\"Poet Agent\",\n","    backstory=\"You are a well-known poet, who enjoys creating high quality poetry.\",\n","    task_description=\"Write a poem about the meaning of life in less than 6 lines\",\n","    task_expected_output=\"Just output the poem, without any title or introductory sentences\",\n",")"],"metadata":{"id":"5EcC1lPoCgIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(agent_example.run())"],"metadata":{"id":"x5MAc-vLClXW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can also associate tools with the agent. Let's create a tool for writing some string into a CSV."],"metadata":{"id":"4dGQ2DZ7DIpV"}},{"cell_type":"code","source":["@tool\n","def write_str_to_txt(string_data: str, txt_filename: str):\n","    \"\"\"\n","    Writes a string to a txt file.\n","\n","    This function takes a string and writes it to a text file. If the file already exists,\n","    it will be overwritten with the new data.\n","\n","    Args:\n","        string_data (str): The string containing the data to be written to the file.\n","        txt_filename (str): The name of the text file to which the data should be written.\n","    \"\"\"\n","    # Write the string data to the text file\n","    with open(txt_filename, mode='w', encoding='utf-8') as file:\n","        file.write(string_data)\n","\n","    print(f\"Data successfully written to {txt_filename}\")"],"metadata":{"id":"ag7PjclbDK7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agent_tool_example = Agent(\n","    name=\"Writer Agent\",\n","    backstory=\"You are a language model specialised in writing text into .txt files\",\n","    task_description=\"Write the string 'This is a Tool Agent' into './tool_agent_example.txt'\",\n","    task_expected_output=\"A .txt file containing the given string\",\n","    tools=write_str_to_txt,\n",")"],"metadata":{"id":"RiGJlCAdDLQk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agent_tool_example.run()"],"metadata":{"id":"hI2-4-H_DMwM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####  Defining Agent Dependencies\n","\n","Let's define two agents now.\n"],"metadata":{"id":"9MLSH7DuDUbq"}},{"cell_type":"code","source":["agent_1 = Agent(\n","    name=\"Poet Agent\",\n","    backstory=\"You are a well-known poet, who enjoys creating high quality poetry.\",\n","    task_description=\"Write a poem about the meaning of life in 4 lines\",\n","    task_expected_output=\"Just output the poem, without any title or introductory sentences\",\n",")\n","\n","agent_2 = Agent(\n","    name=\"Poem Translator Agent\",\n","    backstory=\"You are an expert translator especially skilled in Ancient Greek\",\n","    task_description=\"Translate a poem into Ancient Greek\",\n","    task_expected_output=\"Just output the translated poem and nothing else\"\n",")"],"metadata":{"id":"Y_7dmbybDN7F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can define the agent dependencies using the `>>` operator."],"metadata":{"id":"Z9Q4OGDaDiL1"}},{"cell_type":"code","source":["agent_1 >> agent_2"],"metadata":{"id":"PFvG33ZqDgtz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This means `agent_2` depends on `agent_1`. We can check the dependencies and dependents of both agents."],"metadata":{"id":"AijZG06xDlPW"}},{"cell_type":"code","source":["print(\"Agent 1 dependencies: \", agent_1.dependencies)\n","print(\"Agent 1 dependents: \", agent_1.dependents)\n","print(\"Agent 2 dependencies: \", agent_2.dependencies)\n","print(\"Agent 2 dependents: \", agent_2.dependents)"],"metadata":{"id":"kOw5KXI-DjfX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, if we run `agent_1`, the results will be added to `agent_2`'s context."],"metadata":{"id":"Esj_1gdxDoTX"}},{"cell_type":"code","source":["print(agent_1.run())"],"metadata":{"id":"fF3EwahNDmqR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(agent_2.context)"],"metadata":{"id":"pH63oqMcDpv3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, if we run the second agent, it will use the context received from the previous agent to generate its output."],"metadata":{"id":"aj5zek6RDtP0"}},{"cell_type":"code","source":["print(agent_2.run())"],"metadata":{"id":"1I-KuXEdDrWf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The Crew"],"metadata":{"id":"5N3SprgtDwZT"}},{"cell_type":"code","source":["from collections import deque\n","\n","from colorama import Fore\n","from graphviz import Digraph  # type: ignore\n","\n","class Crew:\n","    \"\"\"\n","    A class representing a crew of agents working together.\n","\n","    This class manages a group of agents, their dependencies, and provides methods\n","    for running the agents in a topologically sorted order.\n","\n","    Attributes:\n","        current_crew (Crew): Class-level variable to track the active Crew context.\n","        agents (list): A list of agents in the crew.\n","    \"\"\"\n","\n","    current_crew = None\n","\n","    def __init__(self):\n","        self.agents = []\n","\n","    def __enter__(self):\n","        \"\"\"\n","        Enters the context manager, setting this crew as the current active context.\n","\n","        Returns:\n","            Crew: The current Crew instance.\n","        \"\"\"\n","        Crew.current_crew = self\n","        return self\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        \"\"\"\n","        Exits the context manager, clearing the active context.\n","\n","        Args:\n","            exc_type: The exception type, if an exception was raised.\n","            exc_val: The exception value, if an exception was raised.\n","            exc_tb: The traceback, if an exception was raised.\n","        \"\"\"\n","        Crew.current_crew = None\n","\n","    def add_agent(self, agent):\n","        \"\"\"\n","        Adds an agent to the crew.\n","\n","        Args:\n","            agent: The agent to be added to the crew.\n","        \"\"\"\n","        self.agents.append(agent)\n","\n","    @staticmethod\n","    def register_agent(agent):\n","        \"\"\"\n","        Registers an agent with the current active crew context.\n","\n","        Args:\n","            agent: The agent to be registered.\n","        \"\"\"\n","        if Crew.current_crew is not None:\n","            Crew.current_crew.add_agent(agent)\n","\n","    def topological_sort(self):\n","        \"\"\"\n","        Performs a topological sort of the agents based on their dependencies.\n","\n","        Returns:\n","            list: A list of agents sorted in topological order.\n","\n","        Raises:\n","            ValueError: If there's a circular dependency among the agents.\n","        \"\"\"\n","        in_degree = {agent: len(agent.dependencies) for agent in self.agents}\n","        queue = deque([agent for agent in self.agents if in_degree[agent] == 0])\n","\n","        sorted_agents = []\n","\n","        while queue:\n","            current_agent = queue.popleft()\n","            sorted_agents.append(current_agent)\n","\n","            for dependent in current_agent.dependents:\n","                in_degree[dependent] -= 1\n","                if in_degree[dependent] == 0:\n","                    queue.append(dependent)\n","\n","        if len(sorted_agents) != len(self.agents):\n","            raise ValueError(\n","                \"Circular dependencies detected among agents, preventing a valid topological sort\"\n","            )\n","\n","        return sorted_agents\n","\n","    def plot(self):\n","        \"\"\"\n","        Plots the Directed Acyclic Graph (DAG) of agents in the crew using Graphviz.\n","\n","        Returns:\n","            Digraph: A Graphviz Digraph object representing the agent dependencies.\n","        \"\"\"\n","        dot = Digraph(format=\"png\")  # Set format to PNG for inline display\n","\n","        # Add nodes and edges for each agent in the crew\n","        for agent in self.agents:\n","            dot.node(agent.name)\n","            for dependency in agent.dependencies:\n","                dot.edge(dependency.name, agent.name)\n","        return dot\n","\n","    def run(self):\n","        \"\"\"\n","        Runs all agents in the crew in topologically sorted order.\n","\n","        This method executes each agent's run method and prints the results.\n","        \"\"\"\n","        sorted_agents = self.topological_sort()\n","        for agent in sorted_agents:\n","            fancy_print(f\"RUNNING AGENT: {agent}\")\n","            print(Fore.RED + f\"{agent.run()}\")\n"],"metadata":{"id":"QTw0fbF5Dufk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's define a sequential crew of agents now."],"metadata":{"id":"POKakLCBD4O5"}},{"cell_type":"code","source":["with Crew() as crew:\n","    agent_1 = Agent(\n","        name=\"Poet Agent\",\n","        backstory=\"You are a well-known poet, who enjoys creating high quality poetry.\",\n","        task_description=\"Write a poem about the meaning of life in less than 6 lines\",\n","        task_expected_output=\"Just output the poem, without any title or introductory sentences\",\n","    )\n","\n","    agent_2 = Agent(\n","        name=\"Poem Translator Agent\",\n","        backstory=\"You are an expert translator especially skilled in Spanish\",\n","        task_description=\"Translate a poem into Spanish\",\n","        task_expected_output=\"Just output the translated poem and nothing else\"\n","    )\n","\n","    agent_3 = Agent(\n","        name=\"Writer Agent\",\n","        backstory=\"You are an expert transcriber, that loves writing poems into txt files\",\n","        task_description=\"You'll receive a Spanish poem in your context. You need to write the poem into './poem.txt' file\",\n","        task_expected_output=\"A txt file containing the greek poem received from the context\",\n","        tools=write_str_to_txt,\n","    )\n","\n","    agent_1 >> agent_2 >> agent_3"],"metadata":{"id":"Is2z1s_lD1Wc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["crew.plot()"],"metadata":{"id":"RaqLS8AFD605"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["crew.run()"],"metadata":{"id":"QtK1N4JID8gE"},"execution_count":null,"outputs":[]}]}